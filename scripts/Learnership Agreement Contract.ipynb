{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "permanent-concrete",
   "metadata": {},
   "source": [
    "**This notebook contains a scripts that creates the database used to prepopulate data to learnership documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-advantage",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "veterinary-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from fuzzywuzzy import process\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import gspread\n",
    "import gspread_dataframe as gd\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-orleans",
   "metadata": {},
   "source": [
    "**Authenticate Gspread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "authorized-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.oauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-extension",
   "metadata": {},
   "source": [
    "**Local Functions Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "broad-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Google Worksheet\n",
    "def import_worksheet(google_spreadsheet, google_worksheet):\n",
    "    \n",
    "    #import worksheet\n",
    "    data_worksheet = gc.open(google_spreadsheet).worksheet(google_worksheet)\n",
    "    \n",
    "    #import data to dataframe\n",
    "    target_df = gd.get_as_dataframe(data_worksheet)\n",
    "    \n",
    "    #remove null rows and columns\n",
    "    target_df = target_df.dropna(how='all')\n",
    "    new_columns = []\n",
    "    for column in target_df.columns:\n",
    "        if 'Unnamed' not in column:\n",
    "            new_columns.append(column)\n",
    "    target_df = target_df[new_columns]\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "\n",
    "#split a column into multiple columns\n",
    "def split_column_num(target_df, column, column_len):\n",
    "    \n",
    "    #create list from 0 to column_len\n",
    "    n_list = list(range(0, column_len))\n",
    "    \n",
    "    #create and populate columns\n",
    "    for i in n_list:\n",
    "        target_df[f'{column}_{i+1}'] = [elem[i] if i < len(elem) else '' for elem in target_df[column]]\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "#split column into two binary columns\n",
    "def column_to_binary(target_df, column, specify='no'):\n",
    "    \n",
    "    #convert column to string\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    \n",
    "    #strip whitespace\n",
    "    target_df[column] = target_df[column].str.strip()\n",
    "    \n",
    "    #create and populate binary columns\n",
    "    target_df[f'{column}_yes'] = ['X' if elem.lower() == 'yes' else '' for elem in target_df[column]]\n",
    "    target_df[f'{column}_no'] = ['X' if elem.lower() == 'no' else '' for elem in target_df[column]]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#split address into component parts\n",
    "def split_address(target_df, column):\n",
    "    \n",
    "    #set column to type string\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    \n",
    "    #split address into street, area, city and strip\n",
    "    for i in range(1,4):\n",
    "        if len(list(target_df[column].str.split(\",\"))[0]) > i - 1:\n",
    "            target_df[f\"{column}_{i}\"] = target_df[column].str.split(\",\").str[i-1] + \",\"\n",
    "            target_df[f\"{column}_{i}\"] = target_df[f\"{column}_{i}\"].str.strip()\n",
    "    \n",
    "    #split addrss into area code and strip\n",
    "    if len(list(target_df[column].str.split(\",\"))[0]) > 3:\n",
    "        target_df[f\"{column}_post_code\"] = target_df[column].str.split(\",\").str[3:].str.join(\"\")\n",
    "        target_df[f\"{column}_post_code\"] = target_df[f\"{column}_post_code\"].str.strip()\n",
    "    \n",
    "    return\n",
    "\n",
    "#convert phone numbers\n",
    "def convert_phone(target_df, column):\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    target_df[column] = target_df[column].astype(float)\n",
    "    target_df[column] = target_df[column].astype(int)\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#convert column type to string\n",
    "def convert_columns_type_string(target_df, columns):\n",
    "    for column in columns:\n",
    "        target_df[column] = target_df[column].astype(str)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "#create age columns\n",
    "def create_age_column(target_df, column):\n",
    "    \n",
    "    #convert dob to datetime formatt\n",
    "    target_df[column] = pd.to_datetime(target_df[column])\n",
    "\n",
    "    #set the date\n",
    "    today = date.today()\n",
    "\n",
    "    #calculate age\n",
    "    target_df['Age'] = today.year - target_df[column].dt.year\n",
    "\n",
    "    #convert age to int\n",
    "    target_df['Age'] = target_df['Age'].astype(int)\n",
    "\n",
    "    #mark if above 35 years\n",
    "    target_df['above_35'] = ['X' if age > 35 else '' for age in target_df['Age']]\n",
    "\n",
    "    #mark if below 36 years\n",
    "    target_df['below_35'] = ['X' if age < 36 else '' for age in target_df['Age']]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#split columns based on column values\n",
    "def split_column(target_df, column):\n",
    "    new_columns = target_df[column].unique()\n",
    "    for new_column in new_columns:\n",
    "        target_df[new_column] = ['X' if elem == new_column else '' for elem in target_df[column]]\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "#split column based on status\n",
    "def split_column_status(target_df, column, value):\n",
    "    #mark if citizen yes\n",
    "    target_df[f\"{column}_yes\"] = ['X' if elem == value else '' for elem in target_df[column]]\n",
    "\n",
    "    #mark if citizen no\n",
    "    target_df[f\"{column}_no\"] = ['X' if elem != value else '' for elem in target_df[column]]\n",
    "\n",
    "    #specify citizenshp status\n",
    "    target_df[f\"{column}_specify\"] = [elem if elem != value else '' for elem in target_df[column]]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#createe prefill tags\n",
    "def create_tags(row, columns):\n",
    "    prefill_tags = []\n",
    "    for column in columns:\n",
    "        tags = {}\n",
    "        tags[\"external_id\"] = column\n",
    "        tags[\"text\"] = row[column]\n",
    "        prefill_tags.append(tags)\n",
    "        \n",
    "    return prefill_tags\n",
    "\n",
    "\n",
    "#add static column\n",
    "def add_static_columns(target_df, column_dict):\n",
    "    for key in column_dict.keys():\n",
    "        target_df[key] = column_dict[key]\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "#subset a dataframe\n",
    "def subset_dataframe(target_df, column, subset_array):\n",
    "    return target_df[target_df[column].isin(subset_array)]\n",
    "\n",
    "\n",
    "#combine sponsor and cohort dataframes\n",
    "def combine_dataframes(target_df, sponsor_df):\n",
    "\n",
    "    for column in sponsor_df.columns:\n",
    "        target_df.loc[:,column] = sponsor_df[column].values[0]\n",
    "    \n",
    "    return\n",
    "\n",
    "#replace nan values\n",
    "def replace_nan(target_df, columns):\n",
    "    target_df.loc[:,columns] = [\"\" for elem in columns]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-positive",
   "metadata": {},
   "source": [
    "**Import Worksheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "tired-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cohort data\n",
    "cohort_df = import_worksheet(\"Cohort 2020 Data\", \"Cohort 2020 Data\")\n",
    "\n",
    "#import sponsorship data\n",
    "sponsor_df = import_worksheet(\"Learnership Agreement Form (Responses)\", \"Form Responses 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-initial",
   "metadata": {},
   "source": [
    "**Update Sponsor Column Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "beneficial-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'Legal Name of Company:': 'employer_legal_name',\n",
    "                           'Trading Name of Company (if different from Legal Name):':'employer_trading_name',\n",
    "                           'Business Address:':'business_address',\n",
    "                           'Postal Address (if different from Business Address):':'business_postal_address',\n",
    "                           'Are you liable for skills development levy?':'skills_development',\n",
    "                           'If yes, what is your SDL number?':'sdl',\n",
    "                           'Name of SETA with which you are registered:':'seta_name',\n",
    "                           'Are you acting as the lead Employer? (the answer to this should be yes if you are the sponsor)': 'lead_employer',\n",
    "                           'Contact Person responsible for Learnership:': 'learnership_contact',\n",
    "                           'Work Phone:': 'employer_phone',\n",
    "                           'Work Fax:':'employer_fax',\n",
    "                           'E-mail Address:': 'employer_email',\n",
    "                           'Full Name of representative responsible for signing the Learnership Agreement:':'employer_fullname',\n",
    "                           'Initials of representative responsible for signing the Learnership Agreement:':'employer_initials'}\n",
    "\n",
    "sponsor_df = sponsor_df.rename(columns=column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-milan",
   "metadata": {},
   "source": [
    "**Update Cohort Column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "synthetic-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_names = {'Home Address - Urban or Rural':'rural_urban', 'Home Language':'home_language', 'Municipality':'municipal',\n",
    "          'Home Address':'home_address', 'Physical Address while studying':'residential_address', 'Disability':'disability',\n",
    "           'Birth Date':'birth_date', \"Firstname\":\"learner_name\", \"Surname\": \"learner_surname\",\n",
    "               \"Postal Address\":\"postal_address\", \"Mobile Number\":\"learner_phone\", \"Student Email\":\"learner_email\",\n",
    "               \"Name of High School\":\"high_school\", \"Year Completed Grade 12\":\"high_school_last_year\",\n",
    "               \"Residential Status (Citizen / Permanent Resident/Asylum Seeker/Work Permit/Study Permit)\":\"citizen\"}\n",
    "\n",
    "cohort_df = cohort_df.rename(columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-farmer",
   "metadata": {},
   "source": [
    "**Convert Columns to Type String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "endangered-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['rural_urban', 'home_language', 'municipal', 'home_address',\n",
    "                'residential_address', 'home_address', 'birth_date']\n",
    "\n",
    "convert_columns_type_string(cohort_df, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-issue",
   "metadata": {},
   "source": [
    "**Get Specific Sponsor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "infrared-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsor_df = subset_dataframe(sponsor_df,'employer_legal_name', ['Q LINK Holdings (Pty) Ltd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-psychology",
   "metadata": {},
   "source": [
    "**Get Specific Students**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "satisfactory-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_df = subset_dataframe(cohort_df,'Active / Not active/Early absorption', ['Active'])\n",
    "\n",
    "cohort_df = subset_dataframe(cohort_df,'Username', ['damangue','lmatsabu','nknkosi','smciwa','tkwayiba','lmoykwen'])\n",
    "len(cohort_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-palace",
   "metadata": {},
   "source": [
    "**Convert Phone Numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "intensive-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnvert phone to type string\n",
    "convert_phone(cohort_df, 'learner_phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-triple",
   "metadata": {},
   "source": [
    "**Split Home Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "reported-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create business postal address\n",
    "split_address(cohort_df, \"home_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44e1dd-9f1e-4cd7-b3f7-65999af605e2",
   "metadata": {},
   "source": [
    "**Split Birthdate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7a727a3b-ead7-4451-9e53-796614361f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new birthdate column\n",
    "cohort_df[\"birth_date\"] = cohort_df[\"birth_date\"].astype(str).str.split(\"-\").str.join(\"\")\n",
    "cohort_df[\"birth_date\"] = [item[-2:] + item[-4:-2] + item[:4] for item in cohort_df[\"birth_date\"]]\n",
    "\n",
    "#use split_column\n",
    "split_column_num(cohort_df, \"birth_date\", 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-diana",
   "metadata": {},
   "source": [
    "**Create ID Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "former-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new id number column\n",
    "cohort_df[\"id\"] = [f\"{id_num}\".split(\"\\\\\")[0].strip() for id_num in cohort_df[\"ID Number/ Passport Number\"]]\n",
    "\n",
    "#use split_column\n",
    "split_column_num(cohort_df, \"id\", 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-resolution",
   "metadata": {},
   "source": [
    "**Create Age Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "pediatric-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create age column\n",
    "#create_age_column(cohort_df, \"birth_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-reynolds",
   "metadata": {},
   "source": [
    "**Create Gender Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "devoted-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip gender column whitespaces\n",
    "cohort_df['Gender'] = cohort_df['Gender'].str.strip()\n",
    "\n",
    "#convert equity column to lowercase\n",
    "cohort_df['Gender'] = cohort_df['Gender'].str.lower()\n",
    "\n",
    "split_column(cohort_df, 'Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-crazy",
   "metadata": {},
   "source": [
    "**Create Equity Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "restricted-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip equity column whitespaces\n",
    "cohort_df['Equity'] = cohort_df['Ethnicity'].str.strip()\n",
    "\n",
    "#convert equity column to lowercase\n",
    "cohort_df['Equity'] = cohort_df['Equity'].str.lower()\n",
    "\n",
    "#reformat equity column\n",
    "cohort_df['Equity'] = cohort_df['Equity'].replace({'black': 'african', 'coloured': 'coloured',\n",
    "                             'indian': 'indian', 'asian': 'african',\n",
    "                             'chinese': 'african', 'white': 'white'})\n",
    "\n",
    "split_column(cohort_df, 'Equity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-differential",
   "metadata": {},
   "source": [
    "**Create Disability Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "growing-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip disability column whitespaces\n",
    "cohort_df['Disability'] = cohort_df['disability'].str.strip()\n",
    "\n",
    "#convert disability column to lowercase\n",
    "cohort_df['Disability'] = cohort_df['disability'].str.lower()\n",
    "\n",
    "#reformat disability column\n",
    "cohort_df['Disability'] = cohort_df['disability'].replace({'no': 'None', 'nan': 'None',\n",
    "                             'yes': 'Disable but unspecified', 'yes - specwearer': 'None',\n",
    "                             'n': 'None', '-': 'None', 'visual impairment - spec wearer': 'None',\n",
    "                             'aspergers / autistic': 'Emotional (behav/psych)', 'patella alta':'Physical (move/stand etc)',\n",
    "                             'y- specwearer': 'None', 'add': 'None', 'visual impairment - spec wearer -': 'None',\n",
    "                             '\\\\n': 'None', 'y - specwearer':'None'})\n",
    "\n",
    "#create disability yes, no, status columns\n",
    "split_column_status(cohort_df, 'disability', 'None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-familiar",
   "metadata": {},
   "source": [
    "**Create Citizenship Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "inside-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip citizenship column\n",
    "cohort_df['citizen'] = cohort_df['citizen'].str.strip()\n",
    "\n",
    "#convert citizenship column to lowercase\n",
    "cohort_df['citizen'] = cohort_df['citizen'].str.lower()\n",
    "\n",
    "#create citizeenship yes, no, status columns\n",
    "split_column_status(cohort_df, 'citizen', 'citizen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-adrian",
   "metadata": {},
   "source": [
    "**Create Full Name and Initials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "korean-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full name and initials\n",
    "def create_full_name(target_df):\n",
    "    target_df['learner_fullname'] = target_df['learner_name'].str.strip().str.lower() + \" \" + target_df['learner_surname'].str.strip().str.lower()\n",
    "    target_df['learner_fullname'] = target_df['learner_fullname'].str.title()\n",
    "    target_df['learner_initials'] = [elem[0][0].upper() + elem[1][0].upper() for elem in target_df['learner_fullname'].str.split(\" \")]\n",
    "    \n",
    "    return\n",
    "\n",
    "create_full_name(cohort_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-checkout",
   "metadata": {},
   "source": [
    "**Create Additional Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "hairy-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_dict = {}\n",
    "\n",
    "#add_static_columns(cohort_df, column_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-trash",
   "metadata": {},
   "source": [
    "**Process SDL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bridal-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsor_df['sdl'] = sponsor_df['sdl'].astype(str)\n",
    "sponsor_df['sdl'] = sponsor_df['sdl'].str.strip()\n",
    "sponsor_df['sdl'] = [elem[-9:] if len(elem) > 9 else elem for elem in sponsor_df['sdl']]\n",
    "\n",
    "#use split_column\n",
    "split_column_num(sponsor_df, \"sdl\", 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-logging",
   "metadata": {},
   "source": [
    "**Process Skills Development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "anticipated-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create skills development binary option\n",
    "column_to_binary(sponsor_df, 'skills_development')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-cradle",
   "metadata": {},
   "source": [
    "**Process Lead Employer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "imperial-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create skills development binary option\n",
    "column_to_binary(sponsor_df, 'lead_employer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-patrol",
   "metadata": {},
   "source": [
    "**Process Business Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "human-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create business address\n",
    "split_address(sponsor_df, \"business_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-tiger",
   "metadata": {},
   "source": [
    "**Process Business Postal Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "vocal-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create business postal address\n",
    "split_address(sponsor_df, \"business_postal_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-harvest",
   "metadata": {},
   "source": [
    "**Create additional Sponsor columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "minus-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine_dataframes(cohort_df, sponsor_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-stable",
   "metadata": {},
   "source": [
    "**Setting columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "subjective-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df[\"grade_12\"] = \"Grade 12\"\n",
    "template_df = pd.read_excel('../qlink_template.xlsx')\n",
    "#template_df.drop(columns=['prefill__white', 'prefill__coloured', 'prefill__business_postal_address_post_code', 'prefill__indian', 'prefill__male'], axis=1)\n",
    "#replace_nan(sponsor_df, ['employer_fax'])\n",
    "template_arr = []\n",
    "\n",
    "for column in template_df.columns:\n",
    "    if column != 'contact_1_email':\n",
    "        if column.replace('prefill__','') not in ['highschool_country', 'highschool_province', 'highschool_town', 'highschool_post_code', 'highschool_suburb', 'highschool_street_1', 'home_post_code', 'white', 'coloured', 'indian']:\n",
    "            template_arr.append(column.replace('prefill__',''))\n",
    "        \n",
    "cohort_df = cohort_df[template_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-terry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "crucial-gardening",
   "metadata": {},
   "source": [
    "**Set Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "seventh-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set template id\n",
    "template_id = 'a70a72ea-fb71-46fd-9bf7-5f4dee7f8a87'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "animal-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send signrequest\n",
    "def send_signrequest(prefill_tags, signers, template_id):\n",
    "    data = {\n",
    "        \"template\": f'https://wethinkcode.signrequest.com/api/v1/templates/{template_id}/',\n",
    "        \"signers\": signers,\n",
    "        \"from_email\": \"no-reply@wethinkcode.co.za\",\n",
    "        \"message\": \"Please sign this document. \\n\\n Kind regards, \\n\\n WeThinkCode_\",\n",
    "        \"subject\": \"WeThinkCode_ has sent you a SignRequest\",\n",
    "        \"who\": \"o\",\n",
    "        \"needs_to_sign\": \"true\",\n",
    "        \"prefill_tags\": prefill_tags,\n",
    "        # Add other parameters here\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        \"https://wethinkocode.signrequest.com/api/v1/signrequest-quick-create/\",\n",
    "        headers={\"Authorization\": \"Token c37da7fb557f0208fd1fbf18dc6896a5bff4e9ef\"},\n",
    "        json=data\n",
    "    )\n",
    "\n",
    "\n",
    "    json_response = json.dumps(response.json(), indent=4)\n",
    "\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        print(f\"Signer: {signers[0]['email']} , Status: {response.status_code}\")\n",
    "        return True\n",
    "    elif response.status_code == 400:\n",
    "        print(\"Not found.\")\n",
    "        print(\"Response: \", json_response)\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-heavy",
   "metadata": {},
   "source": [
    "**Send out sign requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "plain-deputy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signer: damangue@student.wethinkcode.co.za , Status: 201\n",
      "Signer: lmatsabu@student.wethinkcode.co.za , Status: 201\n",
      "Signer: nknkosi@student.wethinkcode.co.za , Status: 201\n",
      "Signer: smciwa@student.wethinkcode.co.za , Status: 201\n",
      "Signer: tkwayiba@student.wethinkcode.co.za , Status: 201\n",
      "Signer: lmoykwen@student.wethinkcode.co.za , Status: 201\n"
     ]
    }
   ],
   "source": [
    "df_columns = cohort_df.columns\n",
    "\n",
    "for index, row in cohort_df.iterrows():\n",
    "    prefill_tags = create_tags(row, df_columns)\n",
    "    #set signers\n",
    "    signers = [{\"email\": row[\"learner_email\"]}]\n",
    "    #signers = [{\"email\": \"mufaro@thoughtquest.co.za\"}]\n",
    "    send_signrequest(prefill_tags, signers, template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "european-basin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner_fullname : Tee-Jay Bird\n",
      "id_number : 0008035361081\n",
      "learner_surname : Bird\n",
      "learner_name : Tee-jay\n",
      "learner_initials : TB\n",
      "rural_urban : Urban\n",
      "municipal : Cape Town Metro\n",
      "home_language : English\n",
      "citizen_no : \n",
      "citizen_yes : X\n",
      "learner_email : tbird@student.wethinkcode.co.za\n",
      "learner_phone : 27659153881\n",
      "home_address : 18 18th Street, Avon, Elsies River, 7490\n",
      "residential_address : 18 18th Street,Avon,Elsies River,7490\n",
      "disability_specify : no\n",
      "disability_no : X\n",
      "disability_yes : \n",
      "coloured : X\n",
      "male : X\n",
      "birth_date : 2000-03-08\n",
      "start_date : 01 March 2021\n"
     ]
    }
   ],
   "source": [
    "for column in cohort_df.columns:\n",
    "    print(f\"{column} : {cohort_df[column].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "monthly-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsor_df[\"employer_trading_name\"] = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-terrace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "diverse-sauce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "curious-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "parliamentary-astronomy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "pressed-support",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c85fcf-13b4-4d39-80ba-98e6b11722ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a18bb-d538-43e9-b2bc-ab9515020191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681a7e2-f399-422d-8289-a11d758d0584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef09588-96f3-46fe-a41e-f59bbaf438d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
