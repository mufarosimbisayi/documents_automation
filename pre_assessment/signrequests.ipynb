{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0373ba43-010b-437c-b345-6f763eb9a9ff",
   "metadata": {},
   "source": [
    "**This script keeps track of a signrequest status for particular documents designated by template ID**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bbaed-7fd7-4e7b-b84d-6103087d8350",
   "metadata": {},
   "source": [
    "**Add local library to path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3f2821-b6c9-4561-af81-d37e8b140834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    sys.path.append(module_path + '/local_library')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d0186-fb66-425d-92e9-dd723d090a14",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e400544d-dc25-4f00-a6d7-a2f521d1d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=1017190226189-f1d5s7cpjrj54u2rqk1ufh9pevguqoap.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from local_library import import_worksheet\n",
    "from local_library import export_worksheet\n",
    "from local_library import signrequest_documents\n",
    "from local_library import upload_to_gdrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9bcc3-70d5-429d-821d-7a594f780fdb",
   "metadata": {},
   "source": [
    "**Download Documents Functions Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d186bb-5789-49b0-98a2-8c14aa92e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_download_df():\n",
    "    \"\"\"\n",
    "    Imports the student and signrequests dfs and merges them\n",
    "    \n",
    "    Args:\n",
    "        N/A\n",
    "        \n",
    "    Returns:\n",
    "        download_df: A dataframe containing merged signrequests and students data.\n",
    "    \"\"\"\n",
    "    \n",
    "    #import signrequest update sheet\n",
    "    signrequests_df = import_worksheet(\"Tech Mentors 2021\", \"Status Updates\")\n",
    "\n",
    "    #import student contract data\n",
    "    student_df = import_worksheet(\"Tech Mentors 2021\", \"Student Data\")\n",
    "    \n",
    "    #create dataframe columns\n",
    "    student_columns = [\"First name\", \"Campus\",\"Surname\", \"Email\"]\n",
    "    signrequests_columns = [\"email\", \"mentor document\", \"mentor contract status\",\"mentor document url\"]\n",
    "    download_columns = [\"First name\", \"Surname\", \"Email\", \"Campus\", \"mentor document\", \"mentor contract status\", \"mentor document url\"]\n",
    "\n",
    "    #subset dataframes using columns\n",
    "    student_df = student_df[student_columns]\n",
    "    signrequests_df = signrequests_df[signrequests_columns]\n",
    "\n",
    "    #merge signrequests with students dataframes\n",
    "    download_df = pd.merge(student_df, signrequests_df, how=\"left\", left_on=\"Email\", right_on=\"email\")\n",
    "    \n",
    "    return download_df[download_columns]\n",
    "\n",
    "\n",
    "def create_folder_ids(download_df):\n",
    "    \"\"\"\n",
    "    Creates folder ids which represent the folder where the document will be saved.\n",
    "    \n",
    "    Args:\n",
    "        target_df: A dataframe which will contain the folder ids.\n",
    "        \n",
    "    Returns:\n",
    "        _: None\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    #map to folder id's\n",
    "    download_folder_map = {\"DBN\":\"1BU1oIZiqUTDaS91Nzmfc5zqTAItUQPMT\", \"CPT\":\"1un85lUNCXLKilWPpAIjfYMGUAoqGFR5k\",\n",
    "                         \"JHB\":\"1EjFSUdpEfyIzUZXJIHP7VoiH0iaorlQm\"}\n",
    "    \n",
    "    #create contract file ids\n",
    "    download_df[\"mentor_folder_id\"] = download_df[\"Campus\"].map(download_folder_map)\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def create_file_names(download_df):\n",
    "    \"\"\"\n",
    "    Creates file names for the files to be saved.\n",
    "    \n",
    "    Args:\n",
    "        download_df: A dataframe containing the data to create the filenames.\n",
    "        \n",
    "    Returns:\n",
    "        _: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #create contract file names\n",
    "    download_df[\"mentor_file_name\"] = download_df[\"First name\"].str.strip() + \" \" + download_df[\"Surname\"].str.strip() + \" \" + \"Mentor-Contract\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_status_columns(download_df):\n",
    "    \"\"\"\n",
    "    Creates status updates columns for the input dataframe.\n",
    "    \n",
    "    Args:\n",
    "        download_df: A dataframe for which the status updates columns will be created.\n",
    "        \n",
    "    Returns:\n",
    "        _: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #create contract status column\n",
    "    download_df[\"mentor contract status\"] = np.nan\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_url_columns(download_df):\n",
    "    \"\"\"\n",
    "    Creates status updates columns for the input dataframe.\n",
    "    \n",
    "    Args:\n",
    "        download_df: A dataframe for which the status updates columns will be created.\n",
    "        \n",
    "    Returns:\n",
    "        _: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #create contract status column\n",
    "    download_df[\"mentor document url\"] = np.nan\n",
    "\n",
    "    pass\n",
    "\n",
    "    \n",
    "def subset_download_df(download_df):\n",
    "    \"\"\"\n",
    "    Subsets the download dataframe using set out columns.\n",
    "    \n",
    "    Args:\n",
    "        download_df: A dataframe for which the status updates columns will be created.\n",
    "        \n",
    "    Returns:\n",
    "        _: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #create download columns\n",
    "    download_columns = [\"First name\", \"Surname\", \"Email\", \"mentor_file_name\", \"mentor contract status\", \"mentor_folder_id\"]\n",
    "\n",
    "    #subset download dataframe using download columns\n",
    "    return download_df[download_columns]\n",
    "    \n",
    "\n",
    "def create_download_df():\n",
    "    \"\"\"\n",
    "    Creates the dataframe containing all the information regarding dowloading files.\n",
    "    \n",
    "    Args:\n",
    "        N/A\n",
    "        \n",
    "    Returns:\n",
    "        download_df: A dataframe containing all the information regarding dowloading files.\n",
    "    \"\"\"\n",
    "    download_df = import_download_df()\n",
    "    create_folder_ids(download_df)\n",
    "    create_file_names(download_df)\n",
    "    create_status_columns(download_df)\n",
    "    download_df = subset_download_df(download_df)\n",
    "\n",
    "    return download_df\n",
    "    \n",
    "    \n",
    "def get_download_df():\n",
    "    \"\"\"\n",
    "    Gets or creates the dataframe containing all data for file downloads.\n",
    "    \n",
    "    Args:\n",
    "        N/A\n",
    "        \n",
    "    Returns:\n",
    "        download_df: A dataframe containing all the information regarding dowloading files.\n",
    "    \"\"\"\n",
    "\n",
    "    #import download update sheet\n",
    "    download_df = import_worksheet(\"Tech Mentors 2021\", \"Downloaded Documents\")\n",
    "    if download_df.empty:\n",
    "        download_df = create_download_df()\n",
    "        export_worksheet(\"Tech Mentors 2021\", \"Downloaded Documents\", download_df)\n",
    "    create_url_columns(download_df)\n",
    "    return download_df\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def bulk_upload_to_gdrive(download_df, target_df, upload_map):\n",
    "    \"\"\"\n",
    "    Bulk uploads contracts to google drive.\n",
    "    \n",
    "    Args:\n",
    "    download_df: A dataframe containing all the links to be downloaded and uploaded.\n",
    "    upload_map: A dictionary containing the column names to be used\n",
    "    \n",
    "    Returns:\n",
    "        N/A\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, row in target_df.iterrows():\n",
    "        \n",
    "        if upload_to_gdrive(row[upload_map[\"document_url\"]], row[upload_map[\"file_name\"]], row[upload_map[\"folder_id\"]]):\n",
    "            download_df.loc[download_df[upload_map[\"file_name\"]] == row[upload_map[\"file_name\"]], upload_map[\"document_status\"]] = 'Saved'\n",
    "        else:\n",
    "            print(f\"The following file could not be uploaded: {row[upload_map['file_name']]}\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54dd799-9e28-45ed-b913-9f6d9d0a3308",
   "metadata": {},
   "source": [
    "**Local Functions Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c844982-2917-4e73-a4a3-c5b0c26267ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_keys(target_columns):\n",
    "    \"\"\"\n",
    "    Checks that all relevant keys are present.\n",
    "    \n",
    "    Args:\n",
    "        target_columns: All columns of a dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        _: A boolean that indicates that all keys are relevant or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'template_id' not in target_columns:\n",
    "        return False\n",
    "    if 'email' not in target_columns:\n",
    "        return False\n",
    "    if 'signrequest_status' not in target_columns:\n",
    "        return False\n",
    "    if 'document_url' not in target_columns:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def add_download_links(download_df, links_df):\n",
    "    \"\"\"\n",
    "    Adds download links to the download df dataframe.\n",
    "    \n",
    "    Args:\n",
    "        download_df: A dataframe containing all the information regarding dowloading files.\n",
    "        links_df: A dataframe containing links to the documents.\n",
    "        \n",
    "    Returns:\n",
    "        updated_download_df: A dataframe resulting in merging download_df with links_df.\n",
    "    \"\"\"\n",
    "    \n",
    "    #filter links\n",
    "    links_df = links_df[links_df['signrequest_status'].isin([\"signed\", \"downloaded\", \"signed and downloaded\"])]\n",
    "    links_df = links_df.dropna()\n",
    "    \n",
    "    #update download_df\n",
    "    for index, row in links_df.iterrows():\n",
    "        condition_email = download_df['Email'] == row['email']\n",
    "        condition_contract = download_df['mentor_file_name'].str.contains(row['template_id'], case=False)\n",
    "        if download_df[condition_email & condition_contract].shape[0] == 1:\n",
    "            download_df.loc[condition_email & condition_contract, 'mentor document url'] = row['document_url']\n",
    "    pass\n",
    "\n",
    "\n",
    "def upload_documents(download_df, links_df):\n",
    "    \"\"\"\n",
    "    Uploads documents to google drive\n",
    "    \n",
    "    Args:\n",
    "        download_df: A dataframe containing all the document data.\n",
    "        links_df: A dataframe containing links to the documents.\n",
    "        \n",
    "    Returns:\n",
    "        N/A\n",
    "    \"\"\"\n",
    "    \n",
    "    campus_document_map = {\"3b9e1d42-2202-4381-9ec6-f232d57cd883\":\"Mentor-Contract\", \"ef1ec8eb-aee9-4246-9cfb-9ecb66b5a3fa\":\"Mentor-Contract\",\n",
    "                      \"febe2cb7-e3d2-4c62-a2f3-6200ea541508\":\"Mentor-Contract\"}\n",
    "    \n",
    "    #check all columns are present\n",
    "    if not relevant_keys(links_df.columns):\n",
    "        return\n",
    "    \n",
    "    links_df['template_id'] = links_df['template_id'].map(campus_document_map)\n",
    "    add_download_links(download_df, links_df)\n",
    "    \n",
    "    #set vars for contract\n",
    "    contract_map = {\"document_url\":\"mentor document url\", \"file_name\":\"mentor_file_name\",\n",
    "                    \"document_status\":\"mentor contract status\", \"folder_id\":\"mentor_folder_id\"}\n",
    "    condition_not_null = download_df['mentor document url'].notnull()\n",
    "    condition_not_saved = download_df['mentor contract status'] != \"Saved\"\n",
    "    contract_df = download_df[condition_not_null & condition_not_saved]\n",
    "    \n",
    "    bulk_upload_to_gdrive(download_df, contract_df, contract_map)\n",
    "    \n",
    "    pass\n",
    "\n",
    "def get_documents_metadata(source_df, download_df):\n",
    "    \"\"\"\n",
    "    Gets API metadata for all signrequests for a particular template.\n",
    "    \n",
    "    Args:\n",
    "        source_df: A dataframe\n",
    "        download_df: A dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        signrequests_list: A list of all relevant SignRequests.\n",
    "    \"\"\"\n",
    "    \n",
    "    #set variables\n",
    "    signrequests_list = []\n",
    "    page_number = 1\n",
    "    \n",
    "    #get unique template ids and emails\n",
    "    emails = get_unique_values(source_df, \"Email\")\n",
    "    template_ids = get_unique_values(source_df, [\"Mentor Contract ID\"])\n",
    "    \n",
    "    #get pages\n",
    "    while True:\n",
    "        specific_filtered_results, next_page = signrequest_documents(emails, template_ids, page_number)\n",
    "        upload_documents(download_df, pd.DataFrame(specific_filtered_results))\n",
    "        signrequests_list += specific_filtered_results\n",
    "        if next_page:\n",
    "            page_number += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return signrequests_list\n",
    "\n",
    "\n",
    "def get_spreadsheet_data():\n",
    "    \"\"\"\n",
    "    Gets and refines the signrequest source data.\n",
    "    \n",
    "    Args:\n",
    "        N/A\n",
    "        \n",
    "    Returns:\n",
    "        source_df: A dataframe containing refined source data used for the signrequests.\n",
    "    \"\"\"\n",
    "    \n",
    "    #import student contract data\n",
    "    student_df = import_worksheet(\"Tech Mentors 2021\", \"Student Data\")\n",
    "\n",
    "    #import contract templates id\n",
    "    template_df = import_worksheet(\"Tech Mentors 2021\", \"Template IDs\")\n",
    "    \n",
    "    #merge student data and template data\n",
    "    source_df = pd.merge(student_df, template_df, on=\"Campus\")\n",
    "    \n",
    "    #list relevant columns\n",
    "    source_df_columns = [\"Email\", \"Mentor Contract ID\"]\n",
    "\n",
    "    #subset columns based on list of relevant columns\n",
    "    source_df = source_df[source_df_columns]\n",
    "    \n",
    "    return source_df\n",
    "\n",
    "\n",
    "def get_unique_values(target_df, columns):\n",
    "    \"\"\"\n",
    "    Gets all the unique values in a(the) specified column(s).\n",
    "    \n",
    "    Args:\n",
    "        target_df: A datframe containing the values in one or more columns.\n",
    "        columns: A string or list of strings representing value containing columns.\n",
    "        \n",
    "    Returns:\n",
    "        _: A list of unique values.\n",
    "    \"\"\"\n",
    "    \n",
    "    target_columns = list(filter(lambda column: True if column in columns else False ,target_df.columns))\n",
    "    return pd.unique(target_df[target_columns].values.ravel('K'))\n",
    "\n",
    "\n",
    "def add_signrequest_status_updates(results_list):\n",
    "    \"\"\"\n",
    "    Adds status updates to the target df based on template id values.\n",
    "    \n",
    "    Args:\n",
    "        results_list: A list of objects containing signrequests data.\n",
    "        \n",
    "    Returns:\n",
    "        new_results_df: A dataframe containing a status updates on signrequests\n",
    "    \"\"\"\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    results_columns = [\"email\", \"template_id\", \"signrequest_status\", \"document_url\"]\n",
    "    contracts_columns = [\"email\", \"mentor document\", \"mentor contract status\", \"mentor document url\"]\n",
    "\n",
    "    contracts_df = results_df[results_columns]\n",
    "    contracts_df.columns = contracts_columns\n",
    "\n",
    "\n",
    "    campus_document_map = {\"ef1ec8eb-aee9-4246-9cfb-9ecb66b5a3fa\":\"CPT Mentor Contract\", \"3b9e1d42-2202-4381-9ec6-f232d57cd883\":\"JHB Mentor COntract\",\n",
    "                      \"febe2cb7-e3d2-4c62-a2f3-6200ea541508\":\"DBN Mentor Contract\"}\n",
    "    contracts_df[\"mentor document\"] = contracts_df[\"mentor document\"].map(campus_document_map)\n",
    "    \n",
    "    return contracts_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be027162-c731-4588-a83a-cfe3da5730d1",
   "metadata": {},
   "source": [
    "**Execute Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72494374-588e-4530-a909-d1b69b1ccd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get signrequests source data\n",
    "source_df = get_spreadsheet_data()\n",
    "\n",
    "#get download dataframe\n",
    "download_df = get_download_df()\n",
    "\n",
    "#get signrequests metadata\n",
    "results_list = get_documents_metadata(source_df, download_df)\n",
    "\n",
    "#add signrequest status updates to source dataframe\n",
    "updated_df = add_signrequest_status_updates(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7f532b-f810-4f50-a3a3-8b37378cfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export updated signrequest source dataframe to google worksheet\n",
    "#export_worksheet(\"Tech Mentors 2021\" ,\"Status Updates\", updated_df)\n",
    "#export_worksheet(\"Tech Mentors 2021\", \"Downloaded Documents\", download_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662eb6ef-80b4-4fd5-80a6-abc3dc150afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef89204-03dd-4058-8942-48664320c06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71887ca4-0d68-4ce5-a7ac-b5fb550e1732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03502a0-58cc-4f9b-b072-bb1074b511d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa29ce-6e0f-4362-984f-b5b1f4c1a534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fd419-f90a-4d7b-8c22-79d8aca282a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d099c-cbed-424b-a27c-0df8572679be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6e5e5-8445-4f99-ba16-dd7ef1242938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "26f4e898-ddac-4679-8fbf-b7e44e91b9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "fbf72a8d-bf24-42d8-9b95-ee4635d1cf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5d96a7b4-480f-4fe1-b481-19bef702bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e6ca416f-49be-473d-8911-f1aff5b1f1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ab66c29c-82f0-4c3a-9474-bd333c1d1f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "87513a5c-a93e-43f4-98c7-ed982271a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3a49f8a1-7540-4dd9-8944-00f15e6bb06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ee691900-68a3-4213-ba5c-80c3aa898178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222b345-410c-4321-a126-bd00637e13b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524dae76-19b5-4913-8cc6-6f1e4caa8200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e1782-b236-478c-ab3b-89cfb94fe791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
