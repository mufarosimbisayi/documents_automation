{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "permanent-concrete",
   "metadata": {},
   "source": [
    "**This notebook contains a scripts that creates the database used to prepopulate data to learnership documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-advantage",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "veterinary-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from fuzzywuzzy import process\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import gspread\n",
    "import gspread_dataframe as gd\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-orleans",
   "metadata": {},
   "source": [
    "**Authenticate Gspread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "authorized-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = gspread.oauth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-extension",
   "metadata": {},
   "source": [
    "**Local Functions Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "broad-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Google Worksheet\n",
    "def import_worksheet(google_spreadsheet, google_worksheet):\n",
    "    \n",
    "    #import worksheet\n",
    "    data_worksheet = gc.open(google_spreadsheet).worksheet(google_worksheet)\n",
    "    \n",
    "    #import data to dataframe\n",
    "    target_df = gd.get_as_dataframe(data_worksheet)\n",
    "    \n",
    "    #remove null rows and columns\n",
    "    target_df = target_df.dropna(how='all')\n",
    "    new_columns = []\n",
    "    for column in target_df.columns:\n",
    "        if 'Unnamed' not in column:\n",
    "            new_columns.append(column)\n",
    "    target_df = target_df[new_columns]\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "\n",
    "#split a column into multiple columns\n",
    "def split_column_num(target_df, column, column_len):\n",
    "    \n",
    "    #create list from 0 to column_len\n",
    "    n_list = list(range(0, column_len))\n",
    "    \n",
    "    #create and populate columns\n",
    "    for i in n_list:\n",
    "        target_df[f'{column}_{i+1}'] = [elem[i] if i < len(elem) else '' for elem in target_df[column]]\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "#split column into two binary columns\n",
    "def column_to_binary(target_df, column, specify='no'):\n",
    "    \n",
    "    #convert column to string\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    \n",
    "    #strip whitespace\n",
    "    target_df[column] = target_df[column].str.strip()\n",
    "    \n",
    "    #create and populate binary columns\n",
    "    target_df[f'{column}_yes'] = ['X' if elem.lower() == 'yes' else '' for elem in target_df[column]]\n",
    "    target_df[f'{column}_no'] = ['X' if elem.lower() == 'no' else '' for elem in target_df[column]]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#split address into component parts\n",
    "def split_address(target_df, column):\n",
    "    \n",
    "    #set column to type string\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    \n",
    "    #split address into street, area, city and strip\n",
    "    for i in range(1,4):\n",
    "        if len(list(target_df[column].str.split(\",\"))[0]) > i - 1:\n",
    "            target_df[f\"{column}_{i}\"] = target_df[column].str.split(\",\").str[i-1] + \",\"\n",
    "            target_df[f\"{column}_{i}\"] = target_df[f\"{column}_{i}\"].str.strip()\n",
    "    \n",
    "    #split addrss into area code and strip\n",
    "    if len(list(target_df[column].str.split(\",\"))[0]) > 3:\n",
    "        target_df[f\"{column}_post_code\"] = target_df[column].str.split(\",\").str[3:].str.join(\"\")\n",
    "        target_df[f\"{column}_post_code\"] = target_df[f\"{column}_post_code\"].str.strip()\n",
    "    \n",
    "    return\n",
    "\n",
    "#convert phone numbers\n",
    "def convert_phone(target_df, column):\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    target_df[column] = target_df[column].astype(float)\n",
    "    target_df[column] = target_df[column].astype(int)\n",
    "    target_df[column] = target_df[column].astype(str)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#convert column type to string\n",
    "def convert_columns_type_string(target_df, columns):\n",
    "    for column in columns:\n",
    "        target_df[column] = target_df[column].astype(str)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "#create age columns\n",
    "def create_age_column(target_df, column):\n",
    "    \n",
    "    #convert dob to datetime formatt\n",
    "    target_df[column] = pd.to_datetime(target_df[column])\n",
    "\n",
    "    #set the date\n",
    "    today = date.today()\n",
    "\n",
    "    #calculate age\n",
    "    target_df['Age'] = today.year - target_df[column].dt.year\n",
    "\n",
    "    #convert age to int\n",
    "    target_df['Age'] = target_df['Age'].astype(int)\n",
    "\n",
    "    #mark if above 35 years\n",
    "    target_df['above_35'] = ['X' if age > 35 else '' for age in target_df['Age']]\n",
    "\n",
    "    #mark if below 36 years\n",
    "    target_df['below_35'] = ['X' if age < 36 else '' for age in target_df['Age']]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#split columns based on column values\n",
    "def split_column(target_df, column):\n",
    "    new_columns = target_df[column].unique()\n",
    "    for new_column in new_columns:\n",
    "        target_df[new_column] = ['X' if elem == new_column else '' for elem in target_df[column]]\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "#split column based on status\n",
    "def split_column_status(target_df, column, value):\n",
    "    #mark if citizen yes\n",
    "    target_df[f\"{column}_yes\"] = ['X' if elem == value else '' for elem in target_df[column]]\n",
    "\n",
    "    #mark if citizen no\n",
    "    target_df[f\"{column}_no\"] = ['X' if elem != value else '' for elem in target_df[column]]\n",
    "\n",
    "    #specify citizenshp status\n",
    "    target_df[f\"{column}_specify\"] = [elem if elem != value else '' for elem in target_df[column]]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#createe prefill tags\n",
    "def create_tags(row, columns):\n",
    "    prefill_tags = []\n",
    "    for column in columns:\n",
    "        tags = {}\n",
    "        tags[\"external_id\"] = column\n",
    "        tags[\"text\"] = row[column]\n",
    "        prefill_tags.append(tags)\n",
    "        \n",
    "    return prefill_tags\n",
    "\n",
    "\n",
    "#add static column\n",
    "def add_static_columns(target_df, column_dict):\n",
    "    for key in column_dict.keys():\n",
    "        target_df[key] = column_dict[key]\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "#subset a dataframe\n",
    "def subset_dataframe(target_df, column, subset_array):\n",
    "    return target_df[target_df[column].isin(subset_array)]\n",
    "\n",
    "\n",
    "#combine sponsor and cohort dataframes\n",
    "def combine_dataframes(target_df, sponsor_df):\n",
    "\n",
    "    for column in sponsor_df.columns:\n",
    "        target_df.loc[:,column] = sponsor_df[column].values[0]\n",
    "    \n",
    "    return\n",
    "\n",
    "#replace nan values\n",
    "def replace_nan(target_df, columns):\n",
    "    target_df.loc[:,columns] = [\"\" for elem in columns]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-positive",
   "metadata": {},
   "source": [
    "**Import Worksheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "tired-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cohort data\n",
    "cohort_df = import_worksheet(\"Cohort 2020 Data\", \"Cohort 2020 Data\")\n",
    "\n",
    "#import sponsorship data\n",
    "sponsor_df = import_worksheet(\"Learnership Agreement Form (Responses)\", \"Form Responses 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-initial",
   "metadata": {},
   "source": [
    "**Update Sponsor Column Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "beneficial-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'Legal Name of Company:': 'employer_legal_name',\n",
    "                           'Trading Name of Company (if different from Legal Name):':'employer_trading_name',\n",
    "                           'Business Address:':'business_address',\n",
    "                           'Postal Address (if different from Business Address):':'business_postal_address',\n",
    "                           'Are you liable for skills development levy?':'skills_development',\n",
    "                           'If yes, what is your SDL number?':'sdl',\n",
    "                           'Name of SETA with which you are registered:':'seta_name',\n",
    "                           'Are you acting as the lead Employer? (the answer to this should be yes if you are the sponsor)': 'lead_employer',\n",
    "                           'Contact Person responsible for Learnership:': 'learnership_contact',\n",
    "                           'Work Phone:': 'employer_phone',\n",
    "                           'Work Fax:':'employer_fax',\n",
    "                           'E-mail Address:': 'employer_email',\n",
    "                           'Full Name of representative responsible for signing the Learnership Agreement:':'employer_fullname',\n",
    "                           'Initials of representative responsible for signing the Learnership Agreement:':'employer_initials'}\n",
    "\n",
    "sponsor_df = sponsor_df.rename(columns=column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-milan",
   "metadata": {},
   "source": [
    "**Update Cohort Column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "synthetic-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_names = {'Home Address - Urban or Rural':'rural_urban', 'Home Language':'home_language', 'Municipality':'municipal',\n",
    "          'Home Address':'home_address', 'Physical Address while studying':'residential_address', 'Disability':'disability',\n",
    "           'Birth Date':'birth_date', \"Firstname\":\"learner_name\", \"Surname\": \"learner_surname\",\n",
    "               \"Postal Address\":\"postal_address\", \"Mobile Number\":\"learner_phone\", \"Student Email\":\"learner_email\",\n",
    "               \"Name of High School\":\"high_school\", \"Year Completed Grade 12\":\"high_school_last_year\",\n",
    "               \"Residential Status (Citizen / Permanent Resident/Asylum Seeker/Work Permit/Study Permit)\":\"citizen\"}\n",
    "\n",
    "cohort_df = cohort_df.rename(columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-farmer",
   "metadata": {},
   "source": [
    "**Convert Columns to Type String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "endangered-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['rural_urban', 'home_language', 'municipal', 'home_address',\n",
    "                'residential_address', 'home_address', 'birth_date']\n",
    "\n",
    "convert_columns_type_string(cohort_df, column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-issue",
   "metadata": {},
   "source": [
    "**Get Specific Sponsor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "infrared-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsor_df = subset_dataframe(sponsor_df,'employer_legal_name', ['Tholangwe (Pty) Ltd '])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-psychology",
   "metadata": {},
   "source": [
    "**Get Specific Students**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "satisfactory-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_df = subset_dataframe(cohort_df,'Active / Not active/Early absorption', ['Active'])\n",
    "\n",
    "cohort_df = subset_dataframe(cohort_df,'learner_email', ['mbkomaqp@student.wethinkcode.co.za'])\n",
    "len(cohort_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-palace",
   "metadata": {},
   "source": [
    "**Convert Phone Numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "intensive-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnvert phone to type string\n",
    "convert_phone(cohort_df, 'learner_phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-triple",
   "metadata": {},
   "source": [
    "**Split Home Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "reported-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create business postal address\n",
    "split_address(cohort_df, \"home_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-diana",
   "metadata": {},
   "source": [
    "**Create ID Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "former-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new id number column\n",
    "cohort_df[\"id\"] = [f\"{id_num}\".split(\"\\\\\")[0].strip() for id_num in cohort_df[\"ID Number/ Passport Number\"]]\n",
    "\n",
    "#use split_column\n",
    "split_column_num(cohort_df, \"id\", 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-resolution",
   "metadata": {},
   "source": [
    "**Create Age Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "pediatric-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create age column\n",
    "create_age_column(cohort_df, \"birth_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-reynolds",
   "metadata": {},
   "source": [
    "**Create Gender Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "devoted-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip gender column whitespaces\n",
    "cohort_df['Gender'] = cohort_df['Gender'].str.strip()\n",
    "\n",
    "#convert equity column to lowercase\n",
    "cohort_df['Gender'] = cohort_df['Gender'].str.lower()\n",
    "\n",
    "split_column(cohort_df, 'Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-crazy",
   "metadata": {},
   "source": [
    "**Create Equity Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "restricted-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip equity column whitespaces\n",
    "cohort_df['Equity'] = cohort_df['Ethnicity'].str.strip()\n",
    "\n",
    "#convert equity column to lowercase\n",
    "cohort_df['Equity'] = cohort_df['Equity'].str.lower()\n",
    "\n",
    "#reformat equity column\n",
    "cohort_df['Equity'] = cohort_df['Equity'].replace({'black': 'african', 'coloured': 'coloured',\n",
    "                             'indian': 'indian', 'asian': 'african',\n",
    "                             'chinese': 'african', 'white': 'white'})\n",
    "\n",
    "split_column(cohort_df, 'Equity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-differential",
   "metadata": {},
   "source": [
    "**Create Disability Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "growing-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip disability column whitespaces\n",
    "cohort_df['Disability'] = cohort_df['disability'].str.strip()\n",
    "\n",
    "#convert disability column to lowercase\n",
    "cohort_df['Disability'] = cohort_df['disability'].str.lower()\n",
    "\n",
    "#reformat disability column\n",
    "cohort_df['Disability'] = cohort_df['disability'].replace({'no': 'None', 'nan': 'None',\n",
    "                             'yes': 'Disable but unspecified', 'yes - specwearer': 'None',\n",
    "                             'n': 'None', '-': 'None', 'visual impairment - spec wearer': 'None',\n",
    "                             'aspergers / autistic': 'Emotional (behav/psych)', 'patella alta':'Physical (move/stand etc)',\n",
    "                             'y- specwearer': 'None', 'add': 'None', 'visual impairment - spec wearer -': 'None',\n",
    "                             '\\\\n': 'None', 'y - specwearer':'None'})\n",
    "\n",
    "#create disability yes, no, status columns\n",
    "split_column_status(cohort_df, 'disability', 'None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-familiar",
   "metadata": {},
   "source": [
    "**Create Citizenship Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "inside-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip citizenship column\n",
    "cohort_df['citizen'] = cohort_df['citizen'].str.strip()\n",
    "\n",
    "#convert citizenship column to lowercase\n",
    "cohort_df['citizen'] = cohort_df['citizen'].str.lower()\n",
    "\n",
    "#create citizeenship yes, no, status columns\n",
    "split_column_status(cohort_df, 'citizen', 'citizen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-adrian",
   "metadata": {},
   "source": [
    "**Create Full Name and Initials**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "korean-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full name and initials\n",
    "def create_full_name(target_df):\n",
    "    target_df['learner_fullname'] = target_df['learner_name'].str.strip().str.lower() + \" \" + target_df['learner_surname'].str.strip().str.lower()\n",
    "    target_df['learner_fullname'] = target_df['learner_fullname'].str.title()\n",
    "    target_df['learner_initials'] = [elem[0][0].upper() + elem[1][0].upper() for elem in target_df['learner_fullname'].str.split(\" \")]\n",
    "    \n",
    "    return\n",
    "\n",
    "create_full_name(cohort_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-checkout",
   "metadata": {},
   "source": [
    "**Create Additional Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "hairy-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_dict = {}\n",
    "\n",
    "#add_static_columns(cohort_df, column_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-trash",
   "metadata": {},
   "source": [
    "**Process SDL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bridal-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsor_df['sdl'] = sponsor_df['sdl'].astype(str)\n",
    "sponsor_df['sdl'] = sponsor_df['sdl'].str.strip()\n",
    "sponsor_df['sdl'] = [elem[-9:] if len(elem) > 9 else elem for elem in sponsor_df['sdl']]\n",
    "\n",
    "#use split_column\n",
    "split_column_num(sponsor_df, \"sdl\", 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-logging",
   "metadata": {},
   "source": [
    "**Process Skills Development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "anticipated-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create skills development binary option\n",
    "column_to_binary(sponsor_df, 'skills_development')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-cradle",
   "metadata": {},
   "source": [
    "**Process Lead Employer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "imperial-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create skills development binary option\n",
    "column_to_binary(sponsor_df, 'lead_employer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-patrol",
   "metadata": {},
   "source": [
    "**Process Business Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "human-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create business address\n",
    "split_address(sponsor_df, \"business_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-tiger",
   "metadata": {},
   "source": [
    "**Process Business Postal Address**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "vocal-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create business postal address\n",
    "split_address(sponsor_df, \"business_postal_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-harvest",
   "metadata": {},
   "source": [
    "**Create additional Sponsor columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "minus-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_dataframes(cohort_df, sponsor_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-stable",
   "metadata": {},
   "source": [
    "**Setting columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "subjective-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_df = pd.read_excel('templates.xlsx')\n",
    "#template_df.drop(columns=['prefill__white', 'prefill__coloured', 'prefill__business_postal_address_post_code', 'prefill__indian', 'prefill__male'], axis=1)\n",
    "replace_nan(sponsor_df, ['employer_fax'])\n",
    "template_arr = []\n",
    "\n",
    "for column in template_df.columns:\n",
    "    if column != 'contact_1_email':\n",
    "        if column not in []:\n",
    "            template_arr.append(column.replace('prefill__',''))\n",
    "        \n",
    "sponsor_df = sponsor_df[template_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "alpha-terry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "crucial-gardening",
   "metadata": {},
   "source": [
    "**Set Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "seventh-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set template id\n",
    "template_id = 'e0a6e37c-55dd-40af-a24d-f9f1e8992d05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "animal-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#send signrequest\n",
    "def send_signrequest(prefill_tags, signers, template_id):\n",
    "    data = {\n",
    "        \"template\": f'https://wethinkcode.signrequest.com/api/v1/templates/{template_id}/',\n",
    "        \"signers\": signers,\n",
    "        \"from_email\": \"no-reply@wethinkcode.co.za\",\n",
    "        \"message\": \"Please sign this document. \\n\\n Kind regards, \\n\\n WeThinkCode_\",\n",
    "        \"subject\": \"WeThinkCode_ has sent you a SignRequest\",\n",
    "        \"who\": \"o\",\n",
    "        \"needs_to_sign\": \"true\",\n",
    "        \"prefill_tags\": prefill_tags,\n",
    "        # Add other parameters here\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        \"https://wethinkocode.signrequest.com/api/v1/signrequest-quick-create/\",\n",
    "        headers={\"Authorization\": \"Token c37da7fb557f0208fd1fbf18dc6896a5bff4e9ef\"},\n",
    "        json=data\n",
    "    )\n",
    "\n",
    "\n",
    "    json_response = json.dumps(response.json(), indent=4)\n",
    "\n",
    "    print(f\"Signer: {signers[0]['email']} , Status: {response.status_code}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-heavy",
   "metadata": {},
   "source": [
    "**Send out sign requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "plain-deputy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signer: outcomes@madeconsortium.com , Status: 201\n"
     ]
    }
   ],
   "source": [
    "df_columns = sponsor_df.columns\n",
    "\n",
    "for index, row in sponsor_df.iterrows():\n",
    "    prefill_tags = create_tags(row, df_columns)\n",
    "    #set signers\n",
    "    signers = [{\"email\": row[\"employer_email\"]}]\n",
    "    send_signrequest(prefill_tags, signers, template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-basin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-numbers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-terrace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-sauce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "curious-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-astronomy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-support",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
